version: 2

config:
  output_dir: ./output/
  show_stacktrace: True
  # show_graph: True
  # log_level: DEBUG
  temp_dir: ./ # <- precedence over dask.temporary-directory
  dask:
    temporary-directory: /tmp
    dataframe:
      backend: pandas
      convert-string: False
      query-planning: False
    multiprocessing:
      context: fork
    distributed:
      scheduler:
        active-memory-manager:
          measure: managed
        processes: True
        worker-saturation: 1.0
      worker:
        memory:
          recent-to-old-time: 5s # 600s
          monitor-interval: 15s
          rebalance:
            measure: managed
          spill: 0.5
          pause: 0.95
          terminate: 0.99
          max-spill: false
      nanny:
        pre-spawn-environ:
          MALLOC_TRIM_THRESHOLD_: 0
  dask_cluster_kwargs:
    n_workers: 4
    threads_per_worker: 1
    memory_limit: 1.2GB
    processes: True

sources:
  attendance:
    # this file isn't included in the repo, but it's a 3+GB file with 100M rows
    # (we use this for performance testing)
    # you can create it locally using https://github.com/memsql/datafiller
    # together with the enclosed big_attendance.sql file
    file: ./sources/big_attendance.tsv
    header_rows: 1

transformations:
  attendance:
    source: $sources.attendance
    operations:
      - operation: map_values
        column: attended
        mapping:
          "TRUE": absent
          "FALSE": present
      - operation: rename_columns
        columns:
          attended: status
          # section: session
      - operation: add_columns
        columns:
          school: 12345

destinations:
  studentSchoolAttendanceEvents:
    source: $transformations.attendance
    template: ./templates/studentSchoolAttendanceEvent.jsont
    extension: jsonl
    linearize: True